{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38502c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Dimensionality reduction\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(f\"‚úÖ TensorFlow version: {tf.__version__}\")\n",
    "print(f\"‚úÖ GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f84893",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12a1a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dental X-ray data\n",
    "data = np.load('../../data/data/Dental-Panaromic-Autoencoder.npz')\n",
    "\n",
    "print(\"Available keys in dataset:\")\n",
    "print(list(data.keys()))\n",
    "\n",
    "# Load images (adjust key name based on actual data)\n",
    "if 'images' in data.keys():\n",
    "    images = data['images']\n",
    "elif 'X' in data.keys():\n",
    "    images = data['X']\n",
    "else:\n",
    "    # Use first available array\n",
    "    key = list(data.keys())[0]\n",
    "    images = data[key]\n",
    "    print(f\"Using key: {key}\")\n",
    "\n",
    "print(f\"\\nImage shape: {images.shape}\")\n",
    "print(f\"Data type: {images.dtype}\")\n",
    "print(f\"Value range: [{images.min():.2f}, {images.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd14f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    axes[i].imshow(images[i], cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'Image {i+1}')\n",
    "\n",
    "plt.suptitle('Sample Dental X-Ray Images', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e42d5f",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8289f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images to [0, 1]\n",
    "if images.max() > 1.0:\n",
    "    images_normalized = images.astype('float32') / 255.0\n",
    "else:\n",
    "    images_normalized = images.astype('float32')\n",
    "\n",
    "# Add channel dimension if needed\n",
    "if len(images_normalized.shape) == 3:\n",
    "    images_normalized = np.expand_dims(images_normalized, axis=-1)\n",
    "\n",
    "print(f\"Normalized shape: {images_normalized.shape}\")\n",
    "print(f\"Value range: [{images_normalized.min():.2f}, {images_normalized.max():.2f}]\")\n",
    "\n",
    "# Split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(images_normalized, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c17cd05",
   "metadata": {},
   "source": [
    "## 3. Model 1: Vanilla Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0897a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Vanilla Autoencoder\n",
    "img_shape = X_train.shape[1:]\n",
    "latent_dim = 128\n",
    "\n",
    "# Encoder\n",
    "encoder_input = layers.Input(shape=img_shape)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoder_input)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Latent space\n",
    "x = layers.Flatten()(x)\n",
    "latent = layers.Dense(latent_dim, activation='relu', name='latent')(x)\n",
    "\n",
    "encoder = models.Model(encoder_input, latent, name='encoder')\n",
    "\n",
    "# Decoder\n",
    "decoder_input = layers.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(np.prod(img_shape[:-1]) // 64 * 128, activation='relu')(decoder_input)\n",
    "x = layers.Reshape((img_shape[0]//8, img_shape[1]//8, 128))(x)\n",
    "x = layers.Conv2DTranspose(128, (3, 3), activation='relu', strides=2, padding='same')(x)\n",
    "x = layers.Conv2DTranspose(64, (3, 3), activation='relu', strides=2, padding='same')(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 3), activation='relu', strides=2, padding='same')(x)\n",
    "decoder_output = layers.Conv2D(img_shape[-1], (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "decoder = models.Model(decoder_input, decoder_output, name='decoder')\n",
    "\n",
    "# Full Autoencoder\n",
    "autoencoder = models.Model(encoder_input, decoder(encoder(encoder_input)), name='autoencoder')\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "print(\"‚úÖ Vanilla Autoencoder built\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e707409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Vanilla Autoencoder\n",
    "history_vanilla = autoencoder.fit(\n",
    "    X_train, X_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, X_test),\n",
    "    callbacks=[EarlyStopping(patience=5, restore_best_weights=True)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5bb56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(history_vanilla.history['loss'], label='Train Loss')\n",
    "axes[0].plot(history_vanilla.history['val_loss'], label='Val Loss')\n",
    "axes[0].set_title('Vanilla Autoencoder - Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(history_vanilla.history['mae'], label='Train MAE')\n",
    "axes[1].plot(history_vanilla.history['val_mae'], label='Val MAE')\n",
    "axes[1].set_title('Vanilla Autoencoder - MAE', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reconstructions\n",
    "n_samples = 5\n",
    "test_samples = X_test[:n_samples]\n",
    "reconstructions = autoencoder.predict(test_samples)\n",
    "\n",
    "fig, axes = plt.subplots(2, n_samples, figsize=(15, 6))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Original\n",
    "    axes[0, i].imshow(test_samples[i].squeeze(), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_title('Original', fontweight='bold')\n",
    "    \n",
    "    # Reconstructed\n",
    "    axes[1, i].imshow(reconstructions[i].squeeze(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_title('Reconstructed', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Vanilla Autoencoder - Reconstructions', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff5d5f3",
   "metadata": {},
   "source": [
    "## 4. Model 2: Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4632f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE Sampling layer\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# VAE Encoder\n",
    "encoder_input = layers.Input(shape=img_shape)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoder_input)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "vae_encoder = models.Model(encoder_input, [z_mean, z_log_var, z], name='vae_encoder')\n",
    "\n",
    "# VAE Decoder (reuse previous decoder)\n",
    "vae = models.Model(encoder_input, decoder(z), name='vae')\n",
    "\n",
    "# VAE Loss\n",
    "reconstruction_loss = tf.reduce_mean(\n",
    "    tf.reduce_sum(keras.losses.binary_crossentropy(encoder_input, vae(encoder_input)), axis=(1, 2))\n",
    ")\n",
    "kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "vae_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "\n",
    "print(\"‚úÖ VAE built\")\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3daf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train VAE\n",
    "history_vae = vae.fit(\n",
    "    X_train, X_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, X_test),\n",
    "    callbacks=[EarlyStopping(patience=5, restore_best_weights=True)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ VAE training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486be2bf",
   "metadata": {},
   "source": [
    "## 5. Model 3: Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305e0ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to training data\n",
    "noise_factor = 0.3\n",
    "X_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\n",
    "X_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\n",
    "\n",
    "X_train_noisy = np.clip(X_train_noisy, 0., 1.)\n",
    "X_test_noisy = np.clip(X_test_noisy, 0., 1.)\n",
    "\n",
    "print(f\"Noisy training data shape: {X_train_noisy.shape}\")\n",
    "\n",
    "# Visualize noisy images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "for i in range(5):\n",
    "    axes[0, i].imshow(X_test[i].squeeze(), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_ylabel('Clean', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    axes[1, i].imshow(X_test_noisy[i].squeeze(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_ylabel('Noisy', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Clean vs Noisy Images', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2456ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Denoising Autoencoder (same architecture as vanilla)\n",
    "denoising_ae = models.Model(encoder_input, decoder(encoder(encoder_input)), name='denoising_autoencoder')\n",
    "denoising_ae.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train on noisy input, clean output\n",
    "history_denoising = denoising_ae.fit(\n",
    "    X_train_noisy, X_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_noisy, X_test),\n",
    "    callbacks=[EarlyStopping(patience=5, restore_best_weights=True)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Denoising Autoencoder training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bb0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize denoising results\n",
    "denoised = denoising_ae.predict(X_test_noisy[:5])\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "\n",
    "for i in range(5):\n",
    "    axes[0, i].imshow(X_test[i].squeeze(), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_ylabel('Original', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    axes[1, i].imshow(X_test_noisy[i].squeeze(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_ylabel('Noisy', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    axes[2, i].imshow(denoised[i].squeeze(), cmap='gray')\n",
    "    axes[2, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[2, i].set_ylabel('Denoised', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Denoising Autoencoder Results', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700bf7d",
   "metadata": {},
   "source": [
    "## 6. Latent Space Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract latent representations\n",
    "latent_representations = encoder.predict(X_test[:500])\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "latent_2d = tsne.fit_transform(latent_representations)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(latent_2d[:, 0], latent_2d[:, 1], alpha=0.6, s=50, c=range(len(latent_2d)), cmap='viridis')\n",
    "plt.colorbar(label='Sample Index')\n",
    "plt.title('t-SNE Visualization of Latent Space', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5786ad3",
   "metadata": {},
   "source": [
    "## 7. Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate reconstruction errors\n",
    "reconstructions = autoencoder.predict(X_test)\n",
    "reconstruction_errors = np.mean(np.square(X_test - reconstructions), axis=(1,2,3))\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(reconstruction_errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Reconstruction Error', fontweight='bold')\n",
    "plt.ylabel('Frequency', fontweight='bold')\n",
    "plt.title('Distribution of Reconstruction Errors', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Mark threshold for anomalies\n",
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "plt.axvline(x=threshold, color='red', linestyle='--', linewidth=2, label=f'95th percentile: {threshold:.4f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(range(len(reconstruction_errors)), reconstruction_errors, alpha=0.5)\n",
    "plt.axhline(y=threshold, color='red', linestyle='--', linewidth=2, label='Anomaly Threshold')\n",
    "plt.xlabel('Sample Index', fontweight='bold')\n",
    "plt.ylabel('Reconstruction Error', fontweight='bold')\n",
    "plt.title('Reconstruction Error by Sample', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "anomalies = np.where(reconstruction_errors > threshold)[0]\n",
    "print(f\"\\nüîç Detected {len(anomalies)} potential anomalies ({len(anomalies)/len(X_test)*100:.1f}% of test set)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcfb434",
   "metadata": {},
   "source": [
    "## 8. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db29e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "vanilla_loss = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
    "denoising_loss = denoising_ae.evaluate(X_test_noisy, X_test, verbose=0)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n1. Vanilla Autoencoder:\")\n",
    "print(f\"   Loss (MSE): {vanilla_loss[0]:.6f}\")\n",
    "print(f\"   MAE: {vanilla_loss[1]:.6f}\")\n",
    "\n",
    "print(f\"\\n2. Variational Autoencoder (VAE):\")\n",
    "print(f\"   Can generate new samples from latent space\")\n",
    "print(f\"   Smoother latent space representation\")\n",
    "\n",
    "print(f\"\\n3. Denoising Autoencoder:\")\n",
    "print(f\"   Loss (MSE): {denoising_loss[0]:.6f}\")\n",
    "print(f\"   MAE: {denoising_loss[1]:.6f}\")\n",
    "print(f\"   Robust to noise, learns cleaner features\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f636556",
   "metadata": {},
   "source": [
    "## 9. Summary and Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09259939",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SESSION 12: AUTOENCODERS - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä DATASET:\")\n",
    "print(f\"   ‚Ä¢ Total images: {len(images):,}\")\n",
    "print(f\"   ‚Ä¢ Image shape: {img_shape}\")\n",
    "print(f\"   ‚Ä¢ Latent dimension: {latent_dim}\")\n",
    "\n",
    "print(\"\\nüéØ MODELS BUILT:\")\n",
    "print(\"   1. Vanilla Autoencoder - Basic reconstruction\")\n",
    "print(\"   2. Variational Autoencoder (VAE) - Generative model\")\n",
    "print(\"   3. Denoising Autoencoder - Noise-robust features\")\n",
    "\n",
    "print(\"\\nüè• MEDICAL IMAGING APPLICATIONS:\")\n",
    "print(\"   ‚úì Image compression and reconstruction\")\n",
    "print(\"   ‚úì Anomaly detection (abnormal X-rays)\")\n",
    "print(\"   ‚úì Image denoising and enhancement\")\n",
    "print(\"   ‚úì Feature extraction for diagnosis\")\n",
    "print(\"   ‚úì Data augmentation (VAE generation)\")\n",
    "\n",
    "print(\"\\nüí° KEY INSIGHTS:\")\n",
    "print(f\"   ‚Ä¢ Compression ratio: {np.prod(img_shape)/latent_dim:.1f}:1\")\n",
    "print(f\"   ‚Ä¢ Anomaly detection threshold: {threshold:.4f}\")\n",
    "print(f\"   ‚Ä¢ Models can reconstruct dental X-rays with high fidelity\")\n",
    "\n",
    "print(\"\\nüéì SKILLS DEMONSTRATED:\")\n",
    "print(\"   ‚úÖ Convolutional autoencoders\")\n",
    "print(\"   ‚úÖ Variational inference (VAE)\")\n",
    "print(\"   ‚úÖ Denoising techniques\")\n",
    "print(\"   ‚úÖ Latent space visualization\")\n",
    "print(\"   ‚úÖ Anomaly detection\")\n",
    "print(\"   ‚úÖ Medical image processing\")\n",
    "print(\"   ‚úÖ Model comparison\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4e35b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "autoencoder.save('../../milestone_3_deep_learning/session_12_autoencoders/models/vanilla_autoencoder.h5')\n",
    "vae.save('../../milestone_3_deep_learning/session_12_autoencoders/models/vae.h5')\n",
    "denoising_ae.save('../../milestone_3_deep_learning/session_12_autoencoders/models/denoising_autoencoder.h5')\n",
    "\n",
    "print(\"‚úÖ All models saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
