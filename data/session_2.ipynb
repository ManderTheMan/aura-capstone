{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49831feb-c496-41dc-9e10-674814b214fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Session 2: Data Processing and Statistical Analysis Tasks\n",
    "\n",
    "**Dataset**: NSMES1988new.csv\n",
    "\n",
    "### Tasks:\n",
    "1. Import relevant Python libraries.\n",
    "2. Import the CSV file – NSMES1988new.csv into a dataframe.\n",
    "3. Perform memory analysis of the new dataframe and compare it with the memory of the dataframe in the previous week and mark your comments.\n",
    "4. Perform the following operations on age and income columns: Multiply age by 10 and income by 10000.\n",
    "5. Perform basic statistical analysis on the new dataframe and generate a brief report on the outcome. Save the dataframe as NSMES1988updated.csv file in the local space for possible future use.\n",
    "6. Invoke describe command on the dataframe and compare that with the basic statistical analysis done in the previous step.\n",
    "7. Indicate which of the columns are not eligible for statistical analysis and indicate possible datatype changes, and report.\n",
    "8. Make changes to the recommended file from previous step (Optional).\n",
    "9. Prepare a brief report and enter it in the mark-up cells of JupyterLab Notebook.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7e8efb-519d-4b7a-b375-99e218075a9e",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1-2: Library Import and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5177464-ede2-49fe-9ebf-8b702265d0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>visits</th>\n",
       "      <th>nvisits</th>\n",
       "      <th>ovisits</th>\n",
       "      <th>novisits</th>\n",
       "      <th>emergency</th>\n",
       "      <th>hospital</th>\n",
       "      <th>health</th>\n",
       "      <th>chronic</th>\n",
       "      <th>adl</th>\n",
       "      <th>region</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>married</th>\n",
       "      <th>school</th>\n",
       "      <th>income</th>\n",
       "      <th>employed</th>\n",
       "      <th>insurance</th>\n",
       "      <th>medicaid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>average</td>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>other</td>\n",
       "      <td>6.9</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>6</td>\n",
       "      <td>2.8810</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>average</td>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>other</td>\n",
       "      <td>7.4</td>\n",
       "      <td>female</td>\n",
       "      <td>yes</td>\n",
       "      <td>10</td>\n",
       "      <td>2.7478</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>poor</td>\n",
       "      <td>4</td>\n",
       "      <td>limited</td>\n",
       "      <td>other</td>\n",
       "      <td>6.6</td>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6532</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>poor</td>\n",
       "      <td>2</td>\n",
       "      <td>limited</td>\n",
       "      <td>other</td>\n",
       "      <td>7.6</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6588</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>average</td>\n",
       "      <td>2</td>\n",
       "      <td>limited</td>\n",
       "      <td>other</td>\n",
       "      <td>7.9</td>\n",
       "      <td>female</td>\n",
       "      <td>yes</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6588</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  visits  nvisits  ovisits  novisits  emergency  hospital  \\\n",
       "0           1       5        0        0         0          0         1   \n",
       "1           2       1        0        2         0          2         0   \n",
       "2           3      13        0        0         0          3         3   \n",
       "3           4      16        0        5         0          1         1   \n",
       "4           5       3        0        0         0          0         0   \n",
       "\n",
       "    health  chronic      adl region  age  gender married  school  income  \\\n",
       "0  average        2   normal  other  6.9    male     yes       6  2.8810   \n",
       "1  average        2   normal  other  7.4  female     yes      10  2.7478   \n",
       "2     poor        4  limited  other  6.6  female      no      10  0.6532   \n",
       "3     poor        2  limited  other  7.6    male     yes       3  0.6588   \n",
       "4  average        2  limited  other  7.9  female     yes       6  0.6588   \n",
       "\n",
       "  employed insurance medicaid  \n",
       "0      yes       yes       no  \n",
       "1       no       yes       no  \n",
       "2       no        no      yes  \n",
       "3       no       yes       no  \n",
       "4       no       yes       no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports and data loading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('outputs/NSMES1988new.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec8ada1-0e60-44b6-ae48-e8cf992ee40b",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: Memory Analysis and Comparison\n",
    "\n",
    "Compare memory usage with Session 1 original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a7a1d26-9fad-4698-9f4d-394a7399b627",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMORY USAGE BEFORE RE-OPTIMIZATION:\n",
      "==================================================\n",
      "Original (Session 1): 2.43 MB\n",
      "Current (unoptimized): 2.43 MB\n",
      "\n",
      "CSV files don't preserve data types.\n",
      "    Need to re-apply optimizations\n",
      "\n",
      "\n",
      "MEMORY USAGE AFTER RE-OPTIMIZATION:\n",
      "==================================================\n",
      "Original (Session 1): 2.43 MB\n",
      "After re-optimization: 0.14 MB\n",
      "Memory Reduction: 2.29 MB\n",
      "Percentage Saved: 94.4%\n",
      "\n",
      "✓ Optimizations successfully re-applied!\n"
     ]
    }
   ],
   "source": [
    "# memory analysis\n",
    "\n",
    "# load both datasets for comparison\n",
    "df_original = pd.read_csv('data/NSMES1988.csv')\n",
    "df = pd.read_csv('outputs/NSMES1988new.csv')\n",
    "\n",
    "# memory before optimization\n",
    "original_memory = df_original.memory_usage(deep=True).sum() / 1024**2\n",
    "current_memory_unoptimized = df.memory_usage(deep=True).sum() / 1024**2\n",
    "\n",
    "print(\"MEMORY USAGE BEFORE RE-OPTIMIZATION:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Original (Session 1): {original_memory:.2f} MB\")\n",
    "print(f\"Current (unoptimized): {current_memory_unoptimized:.2f} MB\")\n",
    "print(f\"\\nCSV files don't preserve data types.\")\n",
    "print(\"    Need to re-apply optimizations\\n\")\n",
    "\n",
    "\n",
    "# RE-APPLY OPTIMIZATIONS\n",
    "# convert categorical columns\n",
    "categorical_cols = ['health', 'gender', 'married', 'region', \n",
    "                    'employed', 'insurance', 'medicaid', 'adl']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "# optimize integer columns\n",
    "int_cols = ['visits', 'nvisits', 'ovisits', 'novisits', \n",
    "            'emergency', 'hospital', 'chronic', 'school']\n",
    "\n",
    "for col in int_cols:\n",
    "    if col in df.columns:\n",
    "        max_val = df[col].max()\n",
    "        min_val = df[col].min()\n",
    "        \n",
    "        if min_val >= 0 and max_val < 255:\n",
    "            df[col] = df[col].astype('uint8')\n",
    "        elif min_val >= -128 and max_val < 127:\n",
    "            df[col] = df[col].astype('int8')\n",
    "        elif min_val >= 0 and max_val < 65535:\n",
    "            df[col] = df[col].astype('uint16')\n",
    "        elif min_val >= -32768 and max_val < 32767:\n",
    "            df[col] = df[col].astype('int16')\n",
    "        else:\n",
    "            df[col] = df[col].astype('int32')\n",
    "\n",
    "# optimize float columns\n",
    "float_cols = ['age', 'income']\n",
    "for col in float_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('float32')\n",
    "\n",
    "# memory AFTER re-optimization\n",
    "current_memory_optimized = df.memory_usage(deep=True).sum() / 1024**2\n",
    "\n",
    "print(\"\\nMEMORY USAGE AFTER RE-OPTIMIZATION:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Original (Session 1): {original_memory:.2f} MB\")\n",
    "print(f\"After re-optimization: {current_memory_optimized:.2f} MB\")\n",
    "print(f\"Memory Reduction: {original_memory - current_memory_optimized:.2f} MB\")\n",
    "print(f\"Percentage Saved: {((original_memory - current_memory_optimized) / original_memory * 100):.1f}%\")\n",
    "\n",
    "print(\"\\n✓ Optimizations successfully re-applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d016b3-ef29-44dc-97de-4db6e4d395f3",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 4: Data Transformation - Age and Income Scaling\n",
    "\n",
    "Correct the scaling issues identified in Session 1:\n",
    "- **Age**: Multiply by 10 (scaled → actual years)\n",
    "- **Income**: Multiply by 10,000 (scaled → actual dollars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0245407d-2259-4c8c-8c90-61ec3eddaf15",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE TRANSFORMATION:\n",
      "==================================================\n",
      "\n",
      "Age Column:\n",
      "  Min: 6.60\n",
      "  Max: 10.90\n",
      "  Mean: 7.40\n",
      "  → Values are scaled (divided by 10)\n",
      "\n",
      "Income Column:\n",
      "  Min: -1.01\n",
      "  Max: 54.84\n",
      "  Mean: 2.53\n",
      "  → Values are in $10,000 units\n",
      "\n",
      "\n",
      "AFTER TRANSFORMATION:\n",
      "==================================================\n",
      "\n",
      "Age Column:\n",
      "  Min: 66.0 years\n",
      "  Max: 109.0 years\n",
      "  Mean: 74.0 years\n",
      "  ✓ Now in actual years\n",
      "\n",
      "Income Column:\n",
      "  Min: $-10,125.00\n",
      "  Max: $548,351.00\n",
      "  Mean: $25,271.32\n",
      "  ✓ Now in actual dollars\n",
      "\n",
      "  NEGATIVE INCOME ANALYSIS:\n",
      "  Total records: 3\n",
      "  Range: $-10,125.00 to $-8,180.00\n",
      "  Percentage: 0.07%\n",
      "\n",
      "✓ Transformation complete!\n",
      "\n",
      "Note: df_untransformed is preserved if you need to reset\n"
     ]
    }
   ],
   "source": [
    "# load fresh copy as baseline (keep this untouched for safety)\n",
    "df_untransformed = pd.read_csv('outputs/NSMES1988new.csv')\n",
    "\n",
    "# drop Unnamed: 0 if it exists\n",
    "if 'Unnamed: 0' in df_untransformed.columns:\n",
    "    df_untransformed = df_untransformed.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# re-apply optimizations to untransformed version\n",
    "categorical_cols = ['health', 'gender', 'married', 'region', \n",
    "                    'employed', 'insurance', 'medicaid', 'adl']\n",
    "for col in categorical_cols:\n",
    "    if col in df_untransformed.columns:\n",
    "        df_untransformed[col] = df_untransformed[col].astype('category')\n",
    "\n",
    "# create working copy for transformation\n",
    "df = df_untransformed.copy()\n",
    "\n",
    "print(\"BEFORE TRANSFORMATION:\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nAge Column:\")\n",
    "print(f\"  Min: {df['age'].min():.2f}\")\n",
    "print(f\"  Max: {df['age'].max():.2f}\")\n",
    "print(f\"  Mean: {df['age'].mean():.2f}\")\n",
    "print(f\"  → Values are scaled (divided by 10)\")\n",
    "\n",
    "print(\"\\nIncome Column:\")\n",
    "print(f\"  Min: {df['income'].min():.2f}\")\n",
    "print(f\"  Max: {df['income'].max():.2f}\")\n",
    "print(f\"  Mean: {df['income'].mean():.2f}\")\n",
    "print(f\"  → Values are in $10,000 units\")\n",
    "\n",
    "# perform transformations on working copy\n",
    "df['age'] = df['age'] * 10\n",
    "df['income'] = df['income'] * 10000\n",
    "\n",
    "print(\"\\n\\nAFTER TRANSFORMATION:\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nAge Column:\")\n",
    "print(f\"  Min: {df['age'].min():.1f} years\")\n",
    "print(f\"  Max: {df['age'].max():.1f} years\")\n",
    "print(f\"  Mean: {df['age'].mean():.1f} years\")\n",
    "print(f\"  ✓ Now in actual years\")\n",
    "\n",
    "print(\"\\nIncome Column:\")\n",
    "print(f\"  Min: ${df['income'].min():,.2f}\")\n",
    "print(f\"  Max: ${df['income'].max():,.2f}\")\n",
    "print(f\"  Mean: ${df['income'].mean():,.2f}\")\n",
    "print(f\"  ✓ Now in actual dollars\")\n",
    "\n",
    "# investigate negative income\n",
    "negative_count = len(df[df['income'] < 0])\n",
    "print(f\"\\n  NEGATIVE INCOME ANALYSIS:\")\n",
    "print(f\"  Total records: {negative_count}\")\n",
    "if negative_count > 0:\n",
    "    print(f\"  Range: ${df[df['income'] < 0]['income'].min():,.2f} to ${df[df['income'] < 0]['income'].max():,.2f}\")\n",
    "    print(f\"  Percentage: {(negative_count / len(df) * 100):.2f}%\")\n",
    "\n",
    "print(\"\\n✓ Transformation complete!\")\n",
    "print(\"\\nNote: df_untransformed is preserved if you need to reset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55b65cc-5150-49b0-8edb-0432510575ff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## Task 5: Basic Statistical Analysis\n",
    "\n",
    "Perform comprehensive statistical calculations on the transformed data.\n",
    "Save results as NSMES1988updated.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fe3311e-a03a-4d1d-9b72-63228eb0f376",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPREHENSIVE STATISTICAL ANALYSIS:\n",
      "==================================================\n",
      "\n",
      "Analyzing 10 numeric columns\n",
      "Total records: 4406\n",
      "\n",
      "            Count      Mean   Median    Mode   Std Dev      Variance      Min  \\\n",
      "visits     4406.0      5.77      4.0     0.0      6.76  4.569000e+01      0.0   \n",
      "nvisits    4406.0      1.62      0.0     0.0      5.32  2.827000e+01      0.0   \n",
      "ovisits    4406.0      0.75      0.0     0.0      3.65  1.334000e+01      0.0   \n",
      "novisits   4406.0      0.54      0.0     0.0      3.88  1.505000e+01      0.0   \n",
      "emergency  4406.0      0.26      0.0     0.0      0.70  5.000000e-01      0.0   \n",
      "hospital   4406.0      0.30      0.0     0.0      0.75  5.600000e-01      0.0   \n",
      "chronic    4406.0      1.54      1.0     1.0      1.35  1.820000e+00      0.0   \n",
      "age        4406.0     74.02     73.0    66.0      6.33  4.012000e+01     66.0   \n",
      "school     4406.0     10.29     11.0    12.0      3.74  1.398000e+01      0.0   \n",
      "income     4406.0  25271.32  16981.5  4320.0  29246.48  8.553564e+08 -10125.0   \n",
      "\n",
      "                Max     Range  Q1 (25%)  Q2 (50%)  Q3 (75%)      IQR  \\\n",
      "visits         89.0      89.0       1.0       4.0       8.0      7.0   \n",
      "nvisits       104.0     104.0       0.0       0.0       1.0      1.0   \n",
      "ovisits       141.0     141.0       0.0       0.0       0.0      0.0   \n",
      "novisits      155.0     155.0       0.0       0.0       0.0      0.0   \n",
      "emergency      12.0      12.0       0.0       0.0       0.0      0.0   \n",
      "hospital        8.0       8.0       0.0       0.0       0.0      0.0   \n",
      "chronic         8.0       8.0       1.0       1.0       2.0      1.0   \n",
      "age           109.0      43.0      69.0      73.0      78.0      9.0   \n",
      "school         18.0      18.0       8.0      11.0      12.0      4.0   \n",
      "income     548351.0  558476.0    9121.5   16981.5   31728.5  22607.0   \n",
      "\n",
      "           Skewness  Kurtosis  \n",
      "visits         3.34     20.23  \n",
      "nvisits        7.59     84.85  \n",
      "ovisits       18.88    570.56  \n",
      "novisits      23.67    769.06  \n",
      "emergency      5.07     46.87  \n",
      "hospital       3.97     22.83  \n",
      "chronic        1.02      1.01  \n",
      "age            0.89      0.55  \n",
      "school        -0.44      0.27  \n",
      "income         5.96     71.70  \n",
      "\n",
      "==================================================\n",
      "✓ Statistical analysis complete\n",
      "✓ Data saved as: NSMES1988updated.csv\n"
     ]
    }
   ],
   "source": [
    "# select only numeric columns for analysis\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "print(\"COMPREHENSIVE STATISTICAL ANALYSIS:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nAnalyzing {len(numeric_cols)} numeric columns\")\n",
    "print(f\"Total records: {len(df)}\\n\")\n",
    "\n",
    "# create a comprehensive statistics dictionary\n",
    "stats_dict = {}\n",
    "\n",
    "for col in numeric_cols:\n",
    "    stats_dict[col] = {\n",
    "        'Count': df[col].count(),\n",
    "        'Mean': df[col].mean(),\n",
    "        'Median': df[col].median(),\n",
    "        'Mode': df[col].mode()[0] if len(df[col].mode()) > 0 else np.nan,\n",
    "        'Std Dev': df[col].std(),\n",
    "        'Variance': df[col].var(),\n",
    "        'Min': df[col].min(),\n",
    "        'Max': df[col].max(),\n",
    "        'Range': df[col].max() - df[col].min(),\n",
    "        'Q1 (25%)': df[col].quantile(0.25),\n",
    "        'Q2 (50%)': df[col].quantile(0.50),\n",
    "        'Q3 (75%)': df[col].quantile(0.75),\n",
    "        'IQR': df[col].quantile(0.75) - df[col].quantile(0.25),\n",
    "        'Skewness': df[col].skew(),\n",
    "        'Kurtosis': df[col].kurtosis()\n",
    "    }\n",
    "\n",
    "# convert to DataFrame for better display\n",
    "stats_df = pd.DataFrame(stats_dict).T\n",
    "\n",
    "# display with nice formatting\n",
    "print(stats_df.round(2))\n",
    "\n",
    "# save the transformed dataframe\n",
    "df.to_csv('outputs/NSMES1988updated.csv', index=False)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"✓ Statistical analysis complete\")\n",
    "print(\"✓ Data saved as: NSMES1988updated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125ef39a-512a-4346-8144-5d0a4dcb71b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Summary Statistics\n",
    "\n",
    "The comprehensive statistical analysis reveals the following about our healthcare dataset:\n",
    "\n",
    "**Population Demographics:**\n",
    "- **Age**: Mean 74 years, Median 73 years\n",
    "  - Dataset focuses on elderly population (66-109 years)\n",
    "  \n",
    "- **Income**: Mean \\$25271.32, Median \\$16981.5\n",
    "  - Income distribution shows positive skew with high earners\n",
    "  - High standard deviation (\\$29246.48) indicates significant economic diversity\n",
    "\n",
    "**Healthcare Utilization Patterns:**\n",
    "- **Physician Visits**: Average 5.7 visits per person\n",
    "- **Emergency Visits**: Average 0.26 visits per person  \n",
    "- **Hospital Stays**: Average 0.3 stays per person\n",
    "- **Chronic Conditions**: Average 1.5 conditions per person\n",
    "\n",
    "\n",
    "**Distribution Characteristics:**\n",
    "\n",
    "| Variable | Skewness | Interpretation |\n",
    "|----------|----------|----------------|\n",
    "| Age | 0.89 | Right |\n",
    "| Income | 5.93 | Right |\n",
    "| Visits | 3.34 | Right |\n",
    "| Hospital | 3.97 | Right |\n",
    "\n",
    "*Skewness interpretation: >0.5 = right-skewed, <-0.5 = left-skewed, -0.5 to 0.5 = fairly symmetric*\n",
    "\n",
    "**Key Observations:**\n",
    "1. Income, Hospital and Emergency had the highest variance.\n",
    "2. Most values mean and medians were very close, indicating no significant outliers.\n",
    "\n",
    "\n",
    "**Data Quality**: All transformations verified. Dataset ready for advanced analysis in Session 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e56a74-5ce6-474c-ac56-a3f43dd398be",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 6: Comparison with Pandas .describe() Method\n",
    "\n",
    "Compare our manual statistical calculations with pandas built-in describe() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b563bf27-8339-4b5e-8f8b-5e7b86394401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PANDAS .describe() METHOD OUTPUT:\n",
      "==================================================\n",
      "        visits  nvisits  ovisits  novisits  emergency  hospital  chronic  \\\n",
      "count  4406.00  4406.00  4406.00   4406.00    4406.00   4406.00  4406.00   \n",
      "mean      5.77     1.62     0.75      0.54       0.26      0.30     1.54   \n",
      "std       6.76     5.32     3.65      3.88       0.70      0.75     1.35   \n",
      "min       0.00     0.00     0.00      0.00       0.00      0.00     0.00   \n",
      "25%       1.00     0.00     0.00      0.00       0.00      0.00     1.00   \n",
      "50%       4.00     0.00     0.00      0.00       0.00      0.00     1.00   \n",
      "75%       8.00     1.00     0.00      0.00       0.00      0.00     2.00   \n",
      "max      89.00   104.00   141.00    155.00      12.00      8.00     8.00   \n",
      "\n",
      "           age   school     income  \n",
      "count  4406.00  4406.00    4406.00  \n",
      "mean     74.02    10.29   25271.32  \n",
      "std       6.33     3.74   29246.48  \n",
      "min      66.00     0.00  -10125.00  \n",
      "25%      69.00     8.00    9121.50  \n",
      "50%      73.00    11.00   16981.50  \n",
      "75%      78.00    12.00   31728.50  \n",
      "max     109.00    18.00  548351.00  \n",
      "\n",
      "\n",
      "COMPARISON: MANUAL vs .describe()\n",
      "==================================================\n",
      "\n",
      "✓ METRICS PROVIDED BY .describe():\n",
      "   • count\n",
      "   • mean\n",
      "   • std\n",
      "   • min\n",
      "   • 25%\n",
      "   • 50%\n",
      "   • 75%\n",
      "   • max\n",
      "\n",
      "✓ ADDITIONAL METRICS FROM MANUAL ANALYSIS:\n",
      "   • mode\n",
      "   • Q1\n",
      "   • Q2\n",
      "   • kurtosis\n",
      "   • median\n",
      "   • IQR\n",
      "   • range\n",
      "   • Q3\n",
      "   • variance\n",
      "   • skewness\n",
      "\n",
      "\n",
      "VERIFICATION (checking if values match):\n",
      "--------------------------------------------------\n",
      "\n",
      "AGE:\n",
      "   Mean:   Manual=74.02, describe()=74.02 ✓ MATCH\n",
      "   Std:    Manual=6.33, describe()=6.33 ✓ MATCH\n",
      "\n",
      "INCOME:\n",
      "   Mean:   Manual=25271.32, describe()=25271.32 ✓ MATCH\n",
      "   Std:    Manual=29246.48, describe()=29246.48 ✓ MATCH\n",
      "\n",
      "VISITS:\n",
      "   Mean:   Manual=5.77, describe()=5.77 ✓ MATCH\n",
      "   Std:    Manual=6.76, describe()=6.76 ✓ MATCH\n",
      "\n",
      "==================================================\n",
      "CONCLUSION:\n",
      "✓ Both methods produce identical results for overlapping metrics\n",
      "✓ Manual analysis provides deeper insights (mode, variance, IQR, skewness, kurtosis)\n",
      "✓ .describe() is faster for quick checks\n",
      "✓ Manual analysis is better for comprehensive reporting\n"
     ]
    }
   ],
   "source": [
    "# use .describe() and compare with manual analysis\n",
    "\n",
    "print(\"PANDAS .describe() METHOD OUTPUT:\")\n",
    "print(\"=\"*50)\n",
    "describe_df = df.describe()\n",
    "print(describe_df.round(2))\n",
    "\n",
    "print(\"\\n\\nCOMPARISON: MANUAL vs .describe()\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# what describe() provides\n",
    "describe_metrics = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "\n",
    "# what our manual analysis provides\n",
    "manual_metrics = ['count', 'mean', 'median', 'mode', 'std', 'variance', \n",
    "                  'min', 'max', 'range', 'Q1', 'Q2', 'Q3', 'IQR', \n",
    "                  'skewness', 'kurtosis']\n",
    "\n",
    "print(\"\\n✓ METRICS PROVIDED BY .describe():\")\n",
    "for metric in describe_metrics:\n",
    "    print(f\"   • {metric}\")\n",
    "\n",
    "print(\"\\n✓ ADDITIONAL METRICS FROM MANUAL ANALYSIS:\")\n",
    "manual_only = set(manual_metrics) - set(['count', 'mean', 'std', 'min', 'max'])\n",
    "for metric in manual_only:\n",
    "    print(f\"   • {metric}\")\n",
    "\n",
    "print(\"\\n\\nVERIFICATION (checking if values match):\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# pick a few columns to verify\n",
    "test_cols = ['age', 'income', 'visits']\n",
    "\n",
    "for col in test_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col.upper()}:\")\n",
    "        manual_mean = stats_df.loc[col, 'Mean']\n",
    "        describe_mean = describe_df.loc['mean', col]\n",
    "        match = \"✓ MATCH\" if abs(manual_mean - describe_mean) < 0.01 else \"✗ MISMATCH\"\n",
    "        print(f\"   Mean:   Manual={manual_mean:.2f}, describe()={describe_mean:.2f} {match}\")\n",
    "        \n",
    "        manual_std = stats_df.loc[col, 'Std Dev']\n",
    "        describe_std = describe_df.loc['std', col]\n",
    "        match = \"✓ MATCH\" if abs(manual_std - describe_std) < 0.01 else \"✗ MISMATCH\"\n",
    "        print(f\"   Std:    Manual={manual_std:.2f}, describe()={describe_std:.2f} {match}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CONCLUSION:\")\n",
    "print(\"✓ Both methods produce identical results for overlapping metrics\")\n",
    "print(\"✓ Manual analysis provides deeper insights (mode, variance, IQR, skewness, kurtosis)\")\n",
    "print(\"✓ .describe() is faster for quick checks\")\n",
    "print(\"✓ Manual analysis is better for comprehensive reporting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b111d499-5154-4d98-a6de-ecf2b2c33ab2",
   "metadata": {},
   "source": [
    "### Comparison Analysis\n",
    "\n",
    "#### Pandas .describe() Method\n",
    "\n",
    "The `.describe()` method provides quick statistical summaries with 8 standard metrics:\n",
    "- Count, Mean, Standard Deviation\n",
    "- Min, 25th percentile, Median (50th), 75th percentile, Max\n",
    "\n",
    "#### Verification Results\n",
    "\n",
    "Comparing manual calculations with `.describe()` for key variables:\n",
    "\n",
    "AGE:\n",
    "   Mean:   Manual=74.02, describe()=74.02 ✓ MATCH\n",
    "   Std:    Manual=6.33, describe()=6.33 ✓ MATCH\n",
    "\n",
    "INCOME:\n",
    "   Mean:   Manual=25271.32, describe()=25271.32 ✓ MATCH\n",
    "   Std:    Manual=29246.48, describe()=29246.48 ✓ MATCH\n",
    "\n",
    "VISITS:\n",
    "   Mean:   Manual=5.77, describe()=5.77 ✓ MATCH\n",
    "   Std:    Manual=6.76, describe()=6.76 ✓ MATCH\n",
    "\n",
    "#### Key Insights\n",
    "\n",
    "**Advantages of .describe():**\n",
    "- Fast and convenient\n",
    "- Standard output format\n",
    "- Good for quick data exploration\n",
    "\n",
    "**Advantages of Manual Analysis:**\n",
    "- Provides additional metrics (Mode, Variance, IQR, Skewness, Kurtosis)\n",
    "- Better understanding of data distribution shape\n",
    "- More control over which statistics to calculate\n",
    "- Essential for detailed reporting\n",
    "\n",
    "**Conclusion:** Both methods are valid and produce identical results for overlapping metrics. Use `.describe()` for quick checks, manual analysis for comprehensive reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f8e120-68a0-44ec-96c4-9e8b4c268f83",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 7: Identify Non-Statistical Columns\n",
    "\n",
    "Determine which columns are not eligible for statistical analysis and recommend appropriate data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "245dcfc6-4a9e-4165-9838-9ed58a9a5aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS NOT ELIGIBLE FOR STATISTICAL ANALYSIS:\n",
      "==================================================\n",
      "\n",
      "Total Columns: 18\n",
      "Numeric Columns: 10\n",
      "Categorical Columns: 8\n",
      "\n",
      "--------------------------------------------------\n",
      "CATEGORICAL COLUMNS DETAILS:\n",
      "--------------------------------------------------\n",
      "   Column Current Type  Unique Values Most Common  Frequency\n",
      "   health     category              3     average       3509\n",
      "      adl     category              2      normal       3507\n",
      "   region     category              4       other       1614\n",
      "   gender     category              2      female       2628\n",
      "  married     category              2         yes       2406\n",
      " employed     category              2          no       3951\n",
      "insurance     category              2         yes       3421\n",
      " medicaid     category              2          no       4004\n",
      "\n",
      "==================================================\n",
      "WHY CATEGORICAL COLUMNS ARE NOT SUITABLE FOR STATISTICS:\n",
      "==================================================\n",
      "\n",
      "1. MEANING: Categorical variables represent groups/categories, not quantities\n",
      "   Example: \"male\" and \"female\" are labels, not numbers\n",
      "\n",
      "2. MATHEMATICAL OPERATIONS: Computing mean, std, variance on categories is meaningless\n",
      "   Example: What's the \"average\" of ['yes', 'no', 'yes', 'no']? → Nonsense!\n",
      "\n",
      "3. APPROPRIATE ANALYSIS: Categorical data requires different methods:\n",
      "   • Frequency counts (how many in each category?)\n",
      "   • Proportions/Percentages (what % in each category?)\n",
      "   • Mode (most common category)\n",
      "   • Cross-tabulations (relationships between categories)\n",
      "   • Chi-square tests (statistical relationships)\n",
      "\n",
      "4. ORDERING: Even if coded as numbers (0/1), categories have no inherent order\n",
      "   Example: male=1, female=2 doesn't mean female is \"greater than\" male\n",
      "\n",
      "\n",
      "==================================================\n",
      "DATA TYPE RECOMMENDATIONS:\n",
      "==================================================\n",
      "   Column Current Type  Unique Values Recommended                                                    Reason\n",
      "   health     category              3    category Only 3 unique values - category dtype is memory efficient\n",
      "      adl     category              2    category Only 2 unique values - category dtype is memory efficient\n",
      "   region     category              4    category Only 4 unique values - category dtype is memory efficient\n",
      "   gender     category              2    category Only 2 unique values - category dtype is memory efficient\n",
      "  married     category              2    category Only 2 unique values - category dtype is memory efficient\n",
      " employed     category              2    category Only 2 unique values - category dtype is memory efficient\n",
      "insurance     category              2    category Only 2 unique values - category dtype is memory efficient\n",
      " medicaid     category              2    category Only 2 unique values - category dtype is memory efficient\n",
      "\n",
      "==================================================\n",
      "SUMMARY:\n",
      "• 10 columns ARE eligible for statistical analysis\n",
      "• 8 columns are NOT eligible (require different analysis methods)\n",
      "• Recommended: Convert 8 columns to category dtype\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Task 7: Identify columns not eligible for statistical analysis\n",
    "\n",
    "print(\"COLUMNS NOT ELIGIBLE FOR STATISTICAL ANALYSIS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Separate columns by type\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "print(f\"\\nTotal Columns: {len(df.columns)}\")\n",
    "print(f\"Numeric Columns: {len(numeric_cols)}\")\n",
    "print(f\"Categorical Columns: {len(categorical_cols)}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"CATEGORICAL COLUMNS DETAILS:\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "categorical_info = []\n",
    "for col in categorical_cols:\n",
    "    unique_count = df[col].nunique()\n",
    "    current_type = df[col].dtype\n",
    "    top_value = df[col].mode()[0] if len(df[col].mode()) > 0 else 'N/A'\n",
    "    top_count = df[col].value_counts().iloc[0] if len(df[col]) > 0 else 0\n",
    "    \n",
    "    categorical_info.append({\n",
    "        'Column': col,\n",
    "        'Current Type': str(current_type),\n",
    "        'Unique Values': unique_count,\n",
    "        'Most Common': top_value,\n",
    "        'Frequency': top_count\n",
    "    })\n",
    "\n",
    "cat_df = pd.DataFrame(categorical_info)\n",
    "print(cat_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"WHY CATEGORICAL COLUMNS ARE NOT SUITABLE FOR STATISTICS:\")\n",
    "print(\"=\"*50)\n",
    "print(\"\"\"\n",
    "1. MEANING: Categorical variables represent groups/categories, not quantities\n",
    "   Example: \"male\" and \"female\" are labels, not numbers\n",
    "\n",
    "2. MATHEMATICAL OPERATIONS: Computing mean, std, variance on categories is meaningless\n",
    "   Example: What's the \"average\" of ['yes', 'no', 'yes', 'no']? → Nonsense!\n",
    "\n",
    "3. APPROPRIATE ANALYSIS: Categorical data requires different methods:\n",
    "   • Frequency counts (how many in each category?)\n",
    "   • Proportions/Percentages (what % in each category?)\n",
    "   • Mode (most common category)\n",
    "   • Cross-tabulations (relationships between categories)\n",
    "   • Chi-square tests (statistical relationships)\n",
    "\n",
    "4. ORDERING: Even if coded as numbers (0/1), categories have no inherent order\n",
    "   Example: male=1, female=2 doesn't mean female is \"greater than\" male\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA TYPE RECOMMENDATIONS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "recommendations = []\n",
    "for col in categorical_cols:\n",
    "    unique_count = df[col].nunique()\n",
    "    current_type = str(df[col].dtype)\n",
    "    \n",
    "    # Recommendation logic\n",
    "    if unique_count <= 10:\n",
    "        recommended = 'category'\n",
    "        reason = f'Only {unique_count} unique values - category dtype is memory efficient'\n",
    "        benefit = f'Memory savings: ~{(df[col].memory_usage(deep=True) / 1024):.1f}KB → ~{(unique_count * 8 / 1024):.1f}KB'\n",
    "    elif unique_count <= 50:\n",
    "        recommended = 'category'\n",
    "        reason = f'{unique_count} unique values - category still beneficial'\n",
    "        benefit = 'Moderate memory savings'\n",
    "    else:\n",
    "        recommended = 'object (keep current)'\n",
    "        reason = f'{unique_count} unique values - too many for category optimization'\n",
    "        benefit = 'Minimal benefit from conversion'\n",
    "    \n",
    "    recommendations.append({\n",
    "        'Column': col,\n",
    "        'Current Type': current_type,\n",
    "        'Unique Values': unique_count,\n",
    "        'Recommended': recommended,\n",
    "        'Reason': reason\n",
    "    })\n",
    "\n",
    "rec_df = pd.DataFrame(recommendations)\n",
    "print(rec_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY:\")\n",
    "print(f\"• {len(numeric_cols)} columns ARE eligible for statistical analysis\")\n",
    "print(f\"• {len(categorical_cols)} columns are NOT eligible (require different analysis methods)\")\n",
    "print(f\"• Recommended: Convert {len([r for r in recommendations if r['Recommended'] == 'category'])} columns to category dtype\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34382a00-8269-4802-9c47-1317347ae16b",
   "metadata": {},
   "source": [
    "### Task 7: Non-Statistical Columns Analysis\n",
    "\n",
    "#### Categorical Columns Found\n",
    "\n",
    "| Column | Current Type | Unique Values | Most Common | Frequency |\n",
    "|--------|--------------|---------------|-------------|-----------|\n",
    "| health | category | 3 | average | 3,509 |\n",
    "| adl | category | 2 | normal | 3,507 |\n",
    "| region | category | 4 | other | 1,614 |\n",
    "| gender | category | 2 | female | 2,628 |\n",
    "| married | category | 2 | yes | 2,406 |\n",
    "| employed | category | 2 | no | 3,951 |\n",
    "| insurance | category | 2 | yes | 3,421 |\n",
    "| medicaid | category | 2 | no | 4,004 |\n",
    "\n",
    "Found 8 categorical columns total. 6 are binary (yes/no or two categories), and 2 have multiple categories (health has 3, region has 4).\n",
    "\n",
    "#### Why We Can't Use Statistics on These\n",
    "\n",
    "These columns have text labels instead of numbers. You can't calculate things like mean or standard deviation on categories - what would \"average gender\" even mean? Instead, we count how many are in each category and look at percentages.\n",
    "\n",
    "For these columns, I'll need to use different methods in Session 3 like counting frequencies, making pivot tables, and looking at how they relate to the numerical columns.\n",
    "\n",
    "#### Data Type Notes\n",
    "\n",
    "All these columns are already set to 'category' type which saves memory. This works well because the same values repeat many times (like \"yes\"/\"no\" or \"male\"/\"female\"), so pandas stores them efficiently as codes instead of repeating the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7598d2d-d95f-4ab3-97a4-d21a8e764fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLYING DATA TYPE OPTIMIZATIONS:\n",
      "==================================================\n",
      "\n",
      "Memory BEFORE optimization: 0.37 MB\n",
      "\n",
      "Applying optimizations...\n",
      "--------------------------------------------------\n",
      "✓ visits: int64 → uint8\n",
      "✓ nvisits: int64 → uint8\n",
      "✓ ovisits: int64 → uint8\n",
      "✓ novisits: int64 → uint8\n",
      "✓ emergency: int64 → uint8\n",
      "✓ hospital: int64 → uint8\n",
      "✓ chronic: int64 → uint8\n",
      "✓ school: int64 → uint8\n",
      "✓ age: float64 → float32\n",
      "✓ income: float64 → float32\n",
      "\n",
      "==================================================\n",
      "OPTIMIZATION RESULTS:\n",
      "==================================================\n",
      "Memory BEFORE: 0.37 MB\n",
      "Memory AFTER:  0.10 MB\n",
      "Memory SAVED:  0.27 MB\n",
      "Reduction:     72.3%\n",
      "\n",
      "==================================================\n",
      "DATA TYPES AFTER OPTIMIZATION:\n",
      "--------------------------------------------------\n",
      "visits          uint8\n",
      "nvisits         uint8\n",
      "ovisits         uint8\n",
      "novisits        uint8\n",
      "emergency       uint8\n",
      "hospital        uint8\n",
      "health       category\n",
      "chronic         uint8\n",
      "adl          category\n",
      "region       category\n",
      "age           float32\n",
      "gender       category\n",
      "married      category\n",
      "school          uint8\n",
      "income        float32\n",
      "employed     category\n",
      "insurance    category\n",
      "medicaid     category\n",
      "dtype: object\n",
      "\n",
      "✓ Optimization complete!\n",
      "Note: df remains unchanged, df_optimized contains optimized version\n"
     ]
    }
   ],
   "source": [
    "# apply recommended data type changes\n",
    "\n",
    "print(\"APPLYING DATA TYPE OPTIMIZATIONS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# check memory BEFORE optimization\n",
    "memory_before = df.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"\\nMemory BEFORE optimization: {memory_before:.2f} MB\")\n",
    "\n",
    "# create optimized copy\n",
    "df_optimized = df.copy()\n",
    "\n",
    "print(\"\\nApplying optimizations...\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# convert categorical columns with few unique values to category dtype\n",
    "categorical_candidates = df_optimized.select_dtypes(include=['object']).columns\n",
    "\n",
    "optimizations_applied = []\n",
    "\n",
    "for col in categorical_candidates:\n",
    "    unique_count = df_optimized[col].nunique()\n",
    "    memory_before_col = df_optimized[col].memory_usage(deep=True) / 1024\n",
    "    \n",
    "    if unique_count <= 10:\n",
    "        df_optimized[col] = df_optimized[col].astype('category')\n",
    "        memory_after_col = df_optimized[col].memory_usage(deep=True) / 1024\n",
    "        savings = memory_before_col - memory_after_col\n",
    "        \n",
    "        optimizations_applied.append({\n",
    "            'Column': col,\n",
    "            'Unique Values': unique_count,\n",
    "            'Before (KB)': f\"{memory_before_col:.2f}\",\n",
    "            'After (KB)': f\"{memory_after_col:.2f}\",\n",
    "            'Savings (KB)': f\"{savings:.2f}\"\n",
    "        })\n",
    "        \n",
    "        print(f\"✓ {col}: object → category ({unique_count} unique values)\")\n",
    "\n",
    "# also optimize integer columns if not already optimized\n",
    "int_cols = df_optimized.select_dtypes(include=['int64']).columns\n",
    "\n",
    "for col in int_cols:\n",
    "    max_val = df_optimized[col].max()\n",
    "    min_val = df_optimized[col].min()\n",
    "    \n",
    "    # Determine optimal integer type\n",
    "    if min_val >= 0 and max_val < 255:\n",
    "        df_optimized[col] = df_optimized[col].astype('uint8')\n",
    "        print(f\"✓ {col}: int64 → uint8\")\n",
    "    elif min_val >= -128 and max_val < 127:\n",
    "        df_optimized[col] = df_optimized[col].astype('int8')\n",
    "        print(f\"✓ {col}: int64 → int8\")\n",
    "    elif min_val >= 0 and max_val < 65535:\n",
    "        df_optimized[col] = df_optimized[col].astype('uint16')\n",
    "        print(f\"✓ {col}: int64 → uint16\")\n",
    "    elif min_val >= -32768 and max_val < 32767:\n",
    "        df_optimized[col] = df_optimized[col].astype('int16')\n",
    "        print(f\"✓ {col}: int64 → int16\")\n",
    "\n",
    "# optimize float columns\n",
    "float_cols = df_optimized.select_dtypes(include=['float64']).columns\n",
    "\n",
    "for col in float_cols:\n",
    "    df_optimized[col] = df_optimized[col].astype('float32')\n",
    "    print(f\"✓ {col}: float64 → float32\")\n",
    "\n",
    "# check memory AFTER optimization\n",
    "memory_after = df_optimized.memory_usage(deep=True).sum() / 1024**2\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"OPTIMIZATION RESULTS:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Memory BEFORE: {memory_before:.2f} MB\")\n",
    "print(f\"Memory AFTER:  {memory_after:.2f} MB\")\n",
    "print(f\"Memory SAVED:  {memory_before - memory_after:.2f} MB\")\n",
    "print(f\"Reduction:     {((memory_before - memory_after) / memory_before * 100):.1f}%\")\n",
    "\n",
    "if optimizations_applied:\n",
    "    print(\"\\n\\nDETAILED CATEGORICAL CONVERSIONS:\")\n",
    "    opt_df = pd.DataFrame(optimizations_applied)\n",
    "    print(opt_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA TYPES AFTER OPTIMIZATION:\")\n",
    "print(\"-\"*50)\n",
    "print(df_optimized.dtypes)\n",
    "\n",
    "# Optional: Save optimized version\n",
    "# df_optimized.to_csv('../outputs/NSMES1988updated_optimized.csv', index=False)\n",
    "# print(\"\\n✓ Optimized data saved as: NSMES1988updated_optimized.csv\")\n",
    "\n",
    "print(\"\\n✓ Optimization complete!\")\n",
    "print(\"Note: df remains unchanged, df_optimized contains optimized version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5398b4b1-7099-4bf3-8e9d-b95872718061",
   "metadata": {},
   "source": [
    "### Task 8: Data Type Optimization (Optional)\n",
    "\n",
    "#### Memory Improvements\n",
    "\n",
    "Applied optimizations to reduce memory usage:\n",
    "\n",
    "**Before optimization**: 0.37 MB  \n",
    "**After optimization**: 0.10 MB  \n",
    "**Saved**: 0.27 MB (72.3% reduction)\n",
    "\n",
    "#### What I Changed\n",
    "\n",
    "**Categorical columns**: Already converted to category type (8 columns)\n",
    "- These were done earlier - saves memory by storing unique values once with integer codes\n",
    "\n",
    "**Integer columns**: Downcasted from int64 to smaller types\n",
    "- Changed columns that only have small numbers (like visit counts) to use uint8 or int16\n",
    "- Most visit counts don't need the huge range that int64 provides\n",
    "\n",
    "**Float columns**: Changed from float64 to float32\n",
    "- Age and income don't need super high precision\n",
    "- float32 is accurate enough and uses half the memory\n",
    "\n",
    "#### Why This Matters\n",
    "\n",
    "The original data types were using way more memory than needed. For example, storing the number \"5\" as int64 uses 8 bytes when uint8 only needs 1 byte. When you have thousands of rows, this adds up fast.\n",
    "\n",
    "#### Important Note\n",
    "\n",
    "When I save this as a CSV and reload it later, these optimizations get lost because CSV only stores the actual values, not the data types. I'll need to re-apply these optimizations at the start of Session 3.\n",
    "\n",
    "Could use .parquet or .pickle files instead to keep the types, but the assignment asks for CSV so I'll just re-optimize each session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0364b7-69ef-4e72-bbc6-8709a59c1d50",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 9: Session 2 Summary Report\n",
    "\n",
    "### Overview\n",
    "\n",
    "This session focused on fixing the scaling issues from Session 1 and doing a full statistical analysis of the dataset. The data is now ready for the more advanced Pandas analysis in Session 3.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Memory Analysis\n",
    "\n",
    "**Starting point**: Loaded NSMES1988new.csv from Session 1\n",
    "\n",
    "**Memory comparison:**\n",
    "- **Original (Session 1)**: 2.43 MB\n",
    "- **After re-optimization**: 0.14 MB\n",
    "- **Memory Reduction**: 2.29 MB\n",
    "- **Percentage Saved**: 94.4%\n",
    "\n",
    "**Key finding**: CSV files don't save the optimized data types, so I had to re-apply the optimizations after loading. Next time I could use .parquet format to keep the types, but sticking with CSV for this project.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Data Transformations\n",
    "\n",
    "#### Age Column\n",
    "- **Before**: 6.6 - 10.9 (divided by 10)\n",
    "- **After**: 66 - 109 years (actual ages)\n",
    "- **How**: Multiplied by 10\n",
    "- **Result**: Now makes sense - this is an elderly population dataset\n",
    "\n",
    "#### Income Column  \n",
    "- **Before**: -1.01 - 54.8 (in \\$10k units)\n",
    "- **After**: -\\$10,100 - \\$548,000 (actual dollars)\n",
    "- **How**: Multiplied by 10,000\n",
    "- **Issue found**: 3 people have negative income - need to investigate why\n",
    "\n",
    "The negative income could be data errors, or it could be real (like business losses). Keeping them in the dataset for now but flagged for review.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Statistical Analysis Results\n",
    "\n",
    "#### Key Demographics\n",
    "\n",
    "**Population Demographics:**\n",
    "- **Age**: Mean 74 years, Median 73 years\n",
    "  - Dataset focuses on elderly population (66-109 years)\n",
    "  \n",
    "- **Income**: Mean \\$25,271.32, Median \\$16,981.50\n",
    "  - Income distribution shows positive skew with high earners\n",
    "  - High standard deviation (\\$29,246.48) indicates significant economic diversity\n",
    "\n",
    "- **Education**: Mean 10.29 years of school (Range: 0-18 years)\n",
    "\n",
    "**Healthcare Utilization Patterns:**\n",
    "- **Physician Visits**: Average 5.77 visits per person\n",
    "- **Emergency Visits**: Average 0.26 visits per person  \n",
    "- **Hospital Stays**: Average 0.30 stays per person\n",
    "- **Chronic Conditions**: Average 1.5 conditions per person\n",
    "\n",
    "Most people have low visit counts, but a few people have very high usage which creates right-skewed distributions.\n",
    "\n",
    "#### Distribution Patterns\n",
    "\n",
    "| Variable | Mean | Median | Skewness | What This Means |\n",
    "|----------|------|--------|----------|-----------------|\n",
    "| Age | 74.0 | 73.0 | 0.89 | Right-skewed |\n",
    "| Income | \\$25,271 | \\$16,982 | 5.96 | Right-skewed |\n",
    "| Visits | 5.77 | 4 | 3.34 | Right-skewed |\n",
    "| Emergency | 0.26 | 0 | 5.07 | Right-skewed |\n",
    "| Hospital | 0.30 | 0 | 3.97 | Right-skewed |\n",
    "\n",
    "**Skewness guide**: Positive = few very high values, Negative = few very low values, Near zero = symmetric\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Manual Calculations vs .describe()\n",
    "\n",
    "I calculated statistics manually (mean, median, std, etc.) and then compared with pandas `.describe()` method. All the overlapping numbers matched perfectly, which validates both approaches work.\n",
    "\n",
    "**Manual method gave me extra info:**\n",
    "- Mode, Variance, Range, IQR\n",
    "- Skewness and Kurtosis (shape of distribution)\n",
    "\n",
    "**Takeaway**: Use `.describe()` for quick checks, manual calculations for detailed reports.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Categorical vs Numerical Variables\n",
    "\n",
    "**Found 8 categorical columns** that can't have statistics calculated on them:\n",
    "- health, adl, region, gender, married, employed, insurance, medicaid\n",
    "\n",
    "These represent groups/labels, not quantities. Can't calculate \"average gender\" - doesn't make sense.\n",
    "\n",
    "**For these I'll use instead:**\n",
    "- Frequency counts (how many in each category)\n",
    "- Percentages  \n",
    "- Cross-tabulations with other variables\n",
    "- Pivot tables in Session 3\n",
    "\n",
    "All of these are already optimized as 'category' data type for memory efficiency.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Memory Optimization\n",
    "\n",
    "Applied optimizations to reduce memory usage:\n",
    "\n",
    "**Changes made:**\n",
    "- Categorical columns: converted to category type (stores efficiently)\n",
    "- Integer columns: downcasted to smaller types (uint8, int16 instead of int64)\n",
    "- Float columns: changed to float32 (still accurate, half the memory)\n",
    "\n",
    "**Before optimization**: 0.37 MB  \n",
    "**After optimization**: 0.10 MB  \n",
    "**Saved**: 0.27 MB (72.3% reduction)\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Key Findings\n",
    "\n",
    "1. **Elderly population**: Everyone is 66-109 years old\n",
    "2. **Economic diversity**: Income ranges from -\\$10,100 to \\$548,000  \n",
    "3. **Right-skewed distributions**: Most healthcare variables show few people with very high usage\n",
    "4. **Data quality**: No missing values, but 3 negative income cases to investigate\n",
    "5. **All transformations verified**: Numbers now make sense and match validation checks\n",
    "\n",
    "---\n",
    "\n",
    "### 8. What's Ready for Session 3\n",
    "\n",
    "**Data saved as**: NSMES1988updated.csv\n",
    "\n",
    "**Ready to analyze:**\n",
    "- Age and income now in correct units\n",
    "- All statistics calculated and documented\n",
    "- Categorical variables identified\n",
    "- Memory optimized\n",
    "\n",
    "**Next steps:**\n",
    "- Pivot tables by demographics\n",
    "- Group analysis by categories\n",
    "- Distribution tables (age/gender, income/region, etc.)\n",
    "- Investigate negative income cases\n",
    "- Look at relationships between variables\n",
    "\n",
    "---\n",
    "\n",
    "### Completion Checklist\n",
    "\n",
    "- [x] Loaded and compared memory usage\n",
    "- [x] Fixed age scaling (×10)\n",
    "- [x] Fixed income scaling (×10,000)\n",
    "- [x] Full statistical analysis\n",
    "- [x] Validated with .describe()\n",
    "- [x] Identified categorical columns\n",
    "- [x] Optimized data types\n",
    "- [x] Saved NSMES1988updated.csv\n",
    "- [x] Documented everything\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b65d69-c324-4433-a80f-9ae4baad1c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
